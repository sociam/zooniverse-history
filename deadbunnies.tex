
notes and todos

different systems have different goals
some are to educate,
others are to make science happen.
 => didn't even explain what a galaxy was.

science team inundated by emails (15,000) before 
 4 person team

did they answer their research 1qustions? did they get papers out of it?
  users are intrinsically motivated to contribute to science
  so the team ``owe it to the users'' t9o get the science out there''


% this is a sad buffer where things that were written go to die >>>>>>>>>>>>>>>>>>>>>>>>>>>

% zooniverse et al publications >
% https://www.zooniverse.org/publications 
% http://mnras.oxfordjournals.org/content/424/4/2442.full

% davis-12 : The distribution of interplanetary dust between 0.96
% and 1.04 au as inferred from impacts on the STEREO spacecraft
% observed by the heliospheric imagers, Davis+ 2012.  

% sayighs : Repeated call types in short-finned pilot whales,
% Globicephala macrorhynchus, Sayigh+ 2012.

%However, designing successful citizen science systems that are mutually beneficial in this way and that can successfully sustain participation and useful results over time can be exceedingly difficult.  The reasons are several: first, due to the emerging nature of the field, key design principles and \emph{best practices} are not yet known or established.  Despite considerable overlap with other kinds of human computation-driven systems (e.g., mechanical turk \cite{}), key differences in the ways that participants engage with citizen science online means that these systems have predominantly required 'starting from scratch', to explicitly consider a greater number of design factors, features and dimensions. For example, although human computation systems often apply extrinsic reward schemes to drive participation, such rewards are usually inappropriate for citizen scientists who are predominantly intrinsically motivated to contribute\cite{extrinsic-vs-intrinsic}. However, since the specific motivations that motivate people typically personal and idiosyncratic \cite{raddick2010galaxy}, understanding  ways to address and engage them can be challenging to design for.  Participants typically interact with with citizen science systems in many different ways beyond merely performing tasks, such as by taking part in discussions, interacting with the science teams, sharing subjects they found interesting, and so forth. meaning that measuring 'success' itself can be diffficult.  Finally, the simple fact that, over time, the more time has elapsed simply forget about any particular system, means that retaining experienced particpants over time.

%  The diversity of projects required different scientific domains, as it involved working closely with zoologists, archaeologists, astronomers, cell biologists, marine biologists, ecologists, biologists, climatologists, geneticists, classicists and historians, among others.

 % Zooniverse also represents the first system in which volunteer contributions directly resulted in the publication of scientific findings in academic journals, contributing findings to at least $P$ published scientific papers.  

% Zooniverse projects are of benefit to zoologists, archaeologists, astronomers, cell biologists, marine biologists, ecologists, biologists, climatologists, geneticists, classicists and historians(and potentially others as well, from retired projects)

% maybe a tad redundant:
%% The goal of the this paper is to, first, document the informal knowledge gathered by the Zoonvierse team pertaining to how to design successful citizen science projects, based on their experience of launching 27 projects since the platform's genesis.  These insights are then discussed in the greater context of human computation, to derive design recommendations and discuss factors that may be responsible for the observations made. We begin with a short history of the project in order to provide readers a context for the following discussion, followed by a grounded dimensional design analysis of particular aspects of Zooniverse's deployment.  Finally, we discuss Zooniverse's team's perspective of the greatest difficulties for building more effective citizen science: $X$, $Y$ and $Z$, and ways that HCI research may be able to help.



% We then discuss the implications of these findings on the design of these forums, and highlight the factors that led to 

% Central to the process of all of these discoveries were the discussion forums, originally principally the Galaxy Zoo Forum, and later \emph{Zooniverse Talk}, described later.  Although there was nothing unique about the set-up or organisation, when paired with the projects, these forums provided both the conduit and context for collaborative discovery, with sufficient flexibility to allow participants to both field each others' questions, and coordinate on more difficult cases, while also socialising and sharing subjects of interest and beauty.

% The first Zooniverse Project, \emph{Galaxy Zoo}, launched as a standalone site without a discussion environment, as the tasks themselves were perceived as the primary method of transforming participation into scientific knowledge (illustrated by the `top path' of Figure \ref{fig:twopaths}). However, when a forum was soon added to handle the flood of questions received by the science team about common artefacts and confusions (such as camera glitches, streaks caused by satellite trails, or problems with the filters) \footnote{The original forum is still active at \url{www.galaxyzooforum.org}}, it became a vital part of the system.  

% Beyond achieving the goals set out to take care of simple questions from new users, the forums also became a place by which users could share and discuss their favourite subjects they encountered, and ultimately, to perform collaborative sensemaking, by sharing, discussing and collecting evidence about unusual subjects that were spotted.  Less than a month after the GalaxyZoo Forum was launched, the citizen participant responsible for the ``Voorwerp'' discovery posted her message that would ultimately mark the project's first citizen-led discovery, of which several more followed.  This second, serendipitous ``path to science'' thus became a major focus for the Zooniverse team, illustrated as the bottom path of Figure \ref{fig:twopaths}. 

% In the following sections, we briefly describe four examples of citizen-initiated investigations, focusing on the ways that citizens contributed to each.  We then discuss the implications of these findings on the design of these forums, and highlight the factors that led to \emph{Talk}, the next iteration of the forum design.

%Therefore, by simply establishing an environment for a community to grow around a common set of tasks, the forums enabled community-driven serendipitous discovery. Here, we provide focused vignettes of four notable citizen-led initiatives, including three confirmed discoveries resulting from them, in order to convey the ways the discussion forums were used.  We then discuss the ways that the Zooniverse team refined the design of the discussion forums to better support distributed collaborative discovery-making.

% Ultimately, this process sparked the discovery of several previously unknown species, planets and phenomena, that have proven thus far among Zooniverse's most significant findings.  Thus, the Zoonivese team see two major ``Paths to Science'', illustrated in Figure \ref{fig:twopaths}. We briefly describe four such phenomena here, highlighting the unique aspects of each discovery, and the roles of the individual parties in each.

% Discussion bunnies >>

% \subsection{Common Myths of Citizen Science}
% \subsubsection{Myth $X$: Putting new users through a `tutorial` is a good idea}
% \subsubsection{Myth $X$: Experienced / advanced users perform better than new users}
% We have seen no support for this hypothesis; in fact an examination of projects ($X$ etc) demonstrated no correlation between duration of use and user performance \cite{simpson2013dynamic}. 
% However, there was evidence that the ways that people get better at using the interface, and that they understand what they are doing with the interface better; for example, with Snapshot Serengeti experience users generally migrate from using the more laborious decision tree interface for describing the animal's features to directly identifying the class and species of animal.

% \subsubsection{Myth $Y$: Citizen science projects have to be `gameified'}
% McGonigal identified four defining elements of a game: a goal, rules, feedback system and voluntary participation. Other features such as leader boards, badges, the `winning' sensation are all used to reinforce these core concepts but do not create a game environment in their own right \cite{mcgonigal2011reality}. To further this gameplay is a state which encourages an optimistic outlook on personal capabilities, partnered with `invigorating rush of activity' \cite{mcgonigal2011reality}. These concepts would support a science citizen, creating a gameplay state to highly motivate and encourage them to undertake difficult challenges. 

% %% The team observed that it took a considerable amount of effort to gameify projects and no net gain occurred over simply
% %% stating "x is really important/beautiful/whatever and we want to study it/save it, please help." Also, it appears that 
% %% for a game to be 'fun' it required an activity which significantly slowed the classification rate, such as in the 'ash game'
% %% that Chris and Rob mentioned while in Oxford. Instead, they opted to use Obfuscated Gameification, where aspects of gameification
% %% were used, such as leaderboards and badges, to encourage participation, without having overt gameification. In addition, users
% %% contribute because of intrinsic motivations such as "I really want to help with science" and their views of what constitutes 
% %% science and what satisfies these intrinsic motivations conflict with gameified projects (? - mentioned by people here but not heard from the team)



% \subsubsection{Myth $Y$: I should include a 'Don't Know' Button}
% % Serengeti blog post - "http://blog.snapshotserengeti.org/2012/12/14/we-need-an-i-dont-know-button/"
% % Needs of science/admin team vs desires of users - not having button far more advantageous for science team and can give tag
% % subjects even though subject may not be clear - e.g, evidently something small even though not sure what.
% % However, talk discussions show that this can lead to misuse of buttons - "nothing here" when there clearly is.
% \subsubsection{Myth $Z$: Participants become domain experts}
% % Related to a previous myth, in that users don't get more accurate with their classifications, so any expertise gain is just as likely to include 'false' expertise - that is, users might learn something about certain galaxies, while simultaneously learning fallacies about other galaxies, in which case they can hardly be said to be experts.

% \subsubsection{Myth $Z$: Beautiful pictures are necessary}
% % Planet Hunters popular, but lacks pictures - In fact uses graphs, which could hardly be called beautiful
% \subsubsection{Myth $Z$: Non-pictorial data are harder to understand}
% % Planet Hunters uses graphs but users do not need to understand the whole graph to classify - Only to identify transit features
% \subsubsection{Myth $Z$: Images don't have to be beautiful and graphs don't have to be scary)}
% There was an initial fear during the development of Planet Hunters that showing participants the light curves as infographics would result in less participation (either by turning participants away from the task) or would simply be unable to perform the task because of being unable to understand what the data represented.  Planet Hunters has been shown, however, just the opposite, and is one of the most successful apps overall.  
% \subsubsection{Myth $Z$: The Data Aren't 'Good Enough'}
% \subsubsection{Myth $Z$: If You Build It, They Will Come}

% It is a common misconception that websites are busy by default. It should go without saying that publicity and attention are required for people to find an online citizen science project. Networks and communities exist online to allow people to discover and share online projects. The Zooniverse was one of the first organisations in this field and has grown a substantial network of people around it (\~860,000 at time of writing).

skdjfdf

% However above simple awareness, any creator of a citizen science project should be aware of the approximate effort required. Most Zooniverse sites enlist the help of tens of thousands of online volunteers. Thus when projects are designed, consideration should be given to the scale of the endeavour being attempted. Taking into account a reasonable expectation of web traffic and the effort any person may put in is difficult (how long is a piece of string?) but important for establishing a project with a realistic end goal within the required time. Simply producing a citizen science website does not guarantee popularity -- or more importantly scientific completion of the intended task.

% % Zooniverse projects draw a substantial number of contributors from the pre-existing community - See Andromeda Project mentioned above, completed in sixteen days due to pre-existing community being informed by newsletter. 
% % Without this community, would have taken much longer. Difficult to form community without 'luck' - Sky at Night and media plugs for various projects, for example, more down to who is on the team. Certainly not users flocking to Zooniverse just because it exists.

% \subsubsection{Myth $Z$: Moderator involvement encourages discussion}
% % comments from Rob and Chris?

% Studies conducted in the educational sector have discovered that contrary to popular belief, instructors (i.e. experts) who contribute often to discussions actually decreased student posts \cite{zydney2012creating}. However, Mazzolini and Maddison propose that this reduction could be a result of more efficient discussion and understanding \cite{mazzolini2007jump}. 

% In a forum context, an interactive post is one which responds or replies to another's message, whereas a participation is the number or length of a post \cite{schrire2006knowledge}. 
% Schrire discovered two distinctive interaction patterns: instructor-centered, messages predominantly responded to the post by the instructor and synergistic, student-student collaboration \cite{schrire2006knowledge}. 

% \subsection{What makes a good citizen science project?}
% \subsubsection{Design Builds Trust}
% % \subsection{Scaling/latency and practical deployment constraints during design}

% \subsection{Comparison to Other Systems}
% % Comparison with Jeremy Bentham project - failed in the sense that required more energy than was gained out of it, 20 people at the end
% % YourPaintings
% % Be A Martian
% % FoldIt

% \subsection{A Heuristic Framework for Citizen Science App Designers}

%% In order to put the observations described above into a more concise, easily communicated and form, we assembled common themes into a multidimensional framework of design heuristics for citizen science system designers, comprising 6 constructs, described below.  Each construct is meant to address a key dimension of the necessary components described earlier, using the observations discussed in findings. The purpose of such a framework is intended both as an artefact for discussion and refinement, and potential practical use by designers seeking to apply insights from the Zooniverse team  currently made by the Zooniverse team.

% attracting new users' attention / expanding the user base
% identifying 'good' projects - understanding what can be turned into a good Citizen Science project
% contextualising the project
%   interestingness/difficulty/conceptual+contextual+narrative threads that tie the tasks together/understand the point of it
%
% performing the task - 
%   - tutorials
%   - elicitation/task vtrtvgtvvt4interface considerations // wide open, specific labeling, decision trees
%   - levels of design and their considerations (aesthetics, challenge, interestingness)
% discussion and collaboration - 
% retaining experienced + most valuable participants
% dealing with new data ~
% distilling knowledge from contributions : (amalgamating responses into thing)

% other/misc
%   transferring interest to other projects
% almost always needs a discussion space

% laucnhing >>>>>>>>>>>

% However above simple awareness, any creator of a citizen science project should be aware of the approximate effort required. Most Zooniverse sites enlist the help of tens of thousands of online volunteers. Thus when projects are designed, consideration should be given to the scale of the endeavour being attempted. Taking into account a reasonable expectation of web traffic and the effort any person may put in is difficult (how long is a piece of string?) but important for establishing a project with a realistic end goal within the required time. Simply producing a citizen science website does not guarantee popularity -- or more importantly scientific completion of the intended task.

% Difficult to form community without 'luck' - Sky at Night and media plugs for various projects, for example, more down to who is on the team. Certainly not users flocking to Zooniverse just because it exists.

% With more than 27 projects launched over just a few years, the Zooniverse platform is host to a series of natural experiments regarding the announcement and subsequent take-up of citizen science projects. There are a large number of variables affecting the potential uptake of any new site including but not limited to; method of announcement (e.g level of press coverage, size of existing community), `stickiness' of proposition (i.e. discovering an exoplanet is generally more exciting as a proposition than differentiating genetic subsamples of nematode worms); difficulty of task; technological requirements (e.g. Does the site work on desktops, tablets, smartphones); and many more.

% TODO: Rob - Add annotations to this plot and talk about events that influenced the profiles. Note that the launch iof Serengeti gives Andromed a boost a week in.
%Add annotations to this plot and talk about events that influenced the profiles. Note that the launch iof Serengeti gives Andromed a boost a week in.

% \subsubsection{Response from Existing Zooniverse Community}

% After the launch of each project, the entire Zooniverse community is emailed an announcement with an explanation of the new project, and how to participate. This pre-existing set of users -- who already have a sign-in for any new Zooniverse site -- is often enough to create a sizeable surge in activity in the early days of a project. In cases where no press coverage exists, this initial boost is sometimes crucial in producing useful data. The case of the Andromeda Project is particularly interesting, as this was the Zooniverse's first new space-based project for almost a year and it did not receive significant press coverage. However, the response from the Zooniverse community was so large that it completed its entire requirement of 1.1 million classifications in sixteen days. Similarly, the initial surge in traffic on the Spacewarps project was impressive (10,000 people contributed 500,000 classifications in its first twenty-four hours) and sustained (more than 10,000 people were visiting the site every day even three weeks later), and it took days for blogs and news sites to pick up the project and publish about it more widely.




% TODO: Can we show a visual example of a call to action versus not?


% http://blog.andromedaproject.org/2013/01/14/first-results-at-aas/ is the source for the change above from "just over two weeks" -> 16 days

% \subsection{Sustaining Engagement}
% Consistent with visitation patterns to most web sites \cite{TODO}, it was observed that visitors to the Zooniverse apps were increasingly likely to leave the site every passing minute on the site, than to stay.  Moreover, since after a user left, the probability that they would ever return was estimated to be at most an odds ratio of $10-to-1$, maximizing the amount of participation meant engaging users with tasks as soon as they first landed.  This had profound implications on the design of the tutorial, as we describe later, getting users acquainted to the system and their task.  The result of optimising this process, however, did allow a significant amount of contributions to be gathered by short-stayers; ultimately, over half of Zooniverse's classifications were performed by users who only visited the site \emph{once}.

%% immediately was a priority for maximizing the amount of potential participation overall.  Even more the likelihood of a later return to the site was (Over half of the classifications were contributed by users who never returned. This of course, has significant implications 
%% From the very first moment that a user arrives on a website, they are more likely to leave than to stay. The faster they can be engaged with participation in the main (citizen science) task, the more people will have participated over all.
%% % TODO this has a significant implication for the training/tutorial phase for getting new users oriented with their task, as users are likely to leave

% \subsection{Engagement: Interestingness x Difficulty x Context}
% By no surprise, a key factor that sustains participant motivation pertains to interesting-ness of the subjects themselves.  For example, those who witness ``beautiful'' galaxies in Galaxy Zoo, or an image containing interesting animals in Snapshot Serengeti, will stay longer and perform more classifications than those who did not see said images. In the case of projects where the subjects may not be inherently interesting, such as Old Weather, use of additional information and context can increase how interesting a subject is to users. In Old Weather, this included log book pages which were not related to weather data, which have resulted in significant numbers of discussions through the project forum.
% To measure the importance of the inherent interest a subject holds for engagement, we identified which subjects were most favourited, and examined whether those users who witnessed these subjects stayed longer, which was significant (Statistical measure). %TODO: Rob please!

% % Another key factor seems to be the graspability of the task - (and this can be challenging; for example, Galaxy Zoo is not about discovering galaxies, but documenting galaxy evolution as a function of their geometry) 

% A third factor pertains to task difficulty. Projects with innately simple to perform tasks (e.g. Ice Hunters, Spacewarps) show much higher classifications-per-user numbers than projects with more difficult tasks (e.g. Milky Way Project, Cyclone Center). The complexity or difficulty of a task does not appear to be correlated with how long users spend on the site in any session, however; Moon Zoo and the Milky Way Project have similar interfaces but very different dwell times. Conversely, Ice Hunters and Old Weather had similar dwell times for many months, despite one being far more complex than the other.

% % Having a clear call-to-action / message
% % Feedback: progress TODO: (move up here from down below)

% %%   % TODO: can we say anything about the effect of the narrative in Old Weather? 
% %%   % evidence in the discussion forums ? 
% %%   %   > i wonder why the handwriting has changed?
% %%   %   > most keen to help each other out -- 

% %% did they create rules - placing limitations to achieving the goal -> make a challenge
% %% what feedback system did they use and what was the overall goal
% %% icebergs/seal hunting : people really wanted a seal. :( 
% %% audio :: 
% %% posters vs 
% %% adding context: old weather
% %% achieving flow state

% Since Galaxy Zoo 2 there have been occasional project-`ometers' created to show progress of the community toward a common goal or project completion. The Planet Hunters `Planetometer' displays the total number of classifications of the project, as well as the number planet candidates discovered. The `Moonometer' shows the cumulative area of the Moon that Moon Zoo has scoured for craters in various units\footnote{Units include Square Miles, Football Fields, Taj Mahals, Switzerlands, Utahs, Texas, Polands, Wales, Whales and others -- see http://www.moonzoo.org/moonometer}. These counters exist on many projects but not all. When counters were present, participants often noticed when project milestones were being approached, as well as when new subjects were introduced.  In the former, participants sometimes posted messages in the forums pointing out that they were approaching the particular milestone to motivate others to pitch in to help.  In the latter, the addition of new data meant that there was significant new work to be done, and participants occasionally posted messages rallying support for starting on the task.  These ``project-o-meters'' also indirectly seemed to support bringing in  participants by attracting journalists and bloggers who often wrote about projects' progress citing these meters, which, in turn drove further traffic to them. 

% milestone - when they didn't want to finish the logs because they didn't want to finish it off


% % In addition to remarks on tutorials, there are other ways to give users feedback about their efforts in citizen science.


% %% TODO: Rob: Anything to say about the way we measure engagement? has this changed? 
% %% \subsection{Measuring Engagement}

% \subsection{Interaction Flow}
% % jump straight to action, no introductory video
% % start with 1 GS, interleave gold standards w/ real things

% \subsubsection{Social Media}
% % favouriting, tweeting, blog posts

% % TODO: Move to -------------> out of this section
% \subsection{Deployment Constraints on Design}

% \subsubsection{Low-Latency Interaction at Scale}
% Creating a responsive online environment requires more sophisticated back end technology. Classification subjects must be drawn out of the whole set on a per-user basis (e.g. users should not see the same subject twice). This creates load on the database every time a new user comes to the classification interface. This situation creates a problem with large datasets, where grabbing a random subject could take up to several seconds; a very long time on a website. The need for reduced load times led to the adoption of \emph{Redis} a database/queue system that can deliver random assets quickly. It also prompted a move away from standard \emph{MySQL} databases per-project and toward a unified \emph{MongoDB} datastore.

% The combination of \emph{MongoDB} and \emph{Redis} means not-only faster websites, but also allows for more complex subject selection rules. For example, it becomes possible to group-up and prioritise subjects, or vary the number of required classifiers over time. Significantly it has allowed for subjects to be retired from classification if they contain nothing of note. This has hugely improved the issue of projects with intrinsically less-appealing or repetitive datasets.  

% % \subsubsection{Other deployment considerations..}



