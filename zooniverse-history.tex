\documentclass{sigchi}

% Use this command to override the default ACM copyright statement (e.g. for preprints). 
% Consult the conference website for the camera-ready copyright statement.
\toappear{}

% Arabic page numbers for submission. 
% Remove this line to eliminate page numbers for the camera ready copy
%\pagenumbering{arabic}


% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage{url}      % llt: nicely formatted URLs
\usepackage{algorithm,algorithmic}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{One Does Not `Simply' Launch a Citizen Science Project: Reflections on Zooniverse, a Multi-Domain Science Platform}
% \title{A Brief History of Zooniverse: Designing for Multi-Domain Citizen Science}

\numberofauthors{1} \author{ (Authors removed for reviewing) }
\maketitle

\begin{abstract}

\end{abstract}

\keywords{Citizen science, crowdsourcing, interface design}

%% TODO 
\category{H.5.m.}{Information Interfaces and Presentation (e.g. HCI)}{Miscellaneous}

%% TODO 
%% \terms{}

\section{Introduction}

Web-based ``citizen-science'' projects have enabled hundreds of
thousands of untrained human volunteers to contribute to open
scientific problems across a variety of domains
\cite{citizen-science}.  The handful of successful systems have
demonstrated that citizen science applications can be valuable both to
participants, as educational tools and cognitively-stimulating
puzzles\cite{citizen-science-in-curricula}, as well as to scientific
researchers who have large unmanageable data sets and problem spaces
\cite{fortson-2011, lintott-08, lintott-11, simpson-12, davis-11}.

% zooniverse et al publications >
% https://www.zooniverse.org/publications 
% http://mnras.oxfordjournals.org/content/424/4/2442.full

% davis-12 : The distribution of interplanetary dust between 0.96
% and 1.04 au as inferred from impacts on the STEREO spacecraft
% observed by the heliospheric imagers, Davis+ 2012.  

% sayighs : Repeated call types in short-finned pilot whales,
% Globicephala macrorhynchus, Sayigh+ 2012.

However, designing successful citizen science systems that can be
mutually beneficial in this way while sustaining participation over
time can be exceedingly difficult.  The reasons are several: first,
due to the emerging nature of the field, key design principles and
\emph{best practices} are not yet known or established.  The unique
aspects of designing for citizen science mean that conventional design
methods pioneered for human computation approaches only apply to a
limited extent.  For example, human computation systems often apply
extrinsic motivation (e.g., direct rewards) to drive participation,
while most citizen science participation systems derive from intrinsic
motivations of individuals \cite{extrinsic-vs-intrinsic}.  Since such
motivations are typically personal and idiosyncratic, designing to
drive sustained attention to them is challenging, requiring an
understanding of their nature and the activities that inspire them
\cite{}.  Moreover, participants naturally engage with citizen science
systems in a variety of different ways, and feature a diversity of
natural competencies, manifesting in great variation among the ways
people interact with the system \cite{raddick}. Finally, the simple
fact that, over time, people are likely to simply forget about any
particular system, as their attention is turned away towards other,
newer systems and activities means that retaining those crucial
participants who have accrued a degree of experience and competence in
their tasks is significantly challenging.

% we want to switch this from interviews to (in crowd). 
% TODO - Ramine - please update this ``retrospective reflective inductive...''
% to something that makes sense - we sat as a group with key team mebers and identified
% themes
In this paper, we contribute a detailed case-study of a unique
citizen-science platform which expanded from a single domain
experiment to what has been considered a ``factory for citizen
science'', an authority for generating successful web applications for
scientists with difficult problems independent of any particular
domain.  Our analysis, conducted as retrospective reflective inductive
thematic analysis with key Zooniverse team members, aimed to identify
the essential lessons learned through the trial and error process that
resulted from designing each app after the previous.  This iterative
process allowed the team to explore design variations at mutiple
levels, from the interface/intraction flow, to the design of social
elements (discussion forums), to external considerations such as ways
to best launch and sustain prolonged engagement through external
communications.

% note: add the fact that this is data analysis not data acquisition
The goal of the this paper is to, first, document the informal
knowledge gathered by the Zoonvierse team pertaining to how to design
successful citizen science projects, based on their experience of
launching 24 projects since the platform's genesis.  These insights
are then discussed in the greater context of human computation, to
derive design recommendations and discuss factors that may be
responsible for the observations made. We begin with a short history
of the project in order to provide readers a context for the following
discussion, followed by a grounded dimensional design analysis of
particular aspects of Zooniverse's deployment.  Finally, we discuss 
Zooniverse's team's perspective of the greatest difficulties for
building more effective citizen science: <X>, <Y> and <Z>, and
ways that HCI research may be able to help.

\section{Background: A Brief History of the Zooniverse}

\emph{TODO: Can someone fill this in?}  The Zooniverse system was
conceived .. \cite{fortson2011galaxy} \emph{TODO TODO --- } 

Unlike citizen-science projects that focus on citizen data collection
(e.g., \cite{crowdsourced-collection}, \cite{}), the focus of
Zooniverse is exclusively citizen \emph{data analysis}, that is, to
get participants to help classify, label and identify information in
large, already extant sets. As documented previously by Lintott et al
\cite{fortson2011galaxy}, the first Zooniverse project, Galaxy
Zoo,designed to engage volunteers in the morphological classification
of images of galaxies, launched in July 2007\cite{galaxyzoo-launch}.



\emph{AND THEN STUFF HAPPENED!}  

%% As of September 2013, the most recent projects were \emph{Worm Watch
%%   Lab}, launched in June 2013, $24$th project to launch

Table \ref{project-summary} lists all of the Zooniverse projects,
launch dates, sizes of data sets and classifications as of September
2013.  Figure $Y$, likewise, illustrates the growth of the project
from June 2007 until September 2013.

% Terminology of Zooniverse 
% See blog post by arfon > 

\begin{table*}
\begin{center}
\caption{Summary of Zooniverse projects past and present.
Notes: The 1.68 million assets in the various Galaxy Zoo projects are not unique, since galaxies in GZ1 were used in subsequent projects.}
\begin{tabular}{lcllclll}
\hline
Project & Status & URL & Launch & Category & Logged-In & Assets & Interface \\
Name &  &  & Date &  & Users &  &  Type \\
\hline
\hline
Galaxy Zoo & Retired & zoo1.galaxyzoo.org & 11 Jul 2007 & Space & 165,000 & 890,000 & Classification \\
\hline
Galaxy Zoo 2 & Retired & zoo2.galaxyzoo.org & ?? ??? 2009 & Space & XX,XXX & 304.122 & Classification \\
Galaxy Zoo Mergers & Retired & mergers.galaxyzoo.org & 23 Nov 2009 & Space & 20,588 & 58,956 & Classification \\
\hline
Galaxy Zoo Supernova & Retired & supernova.galaxyzoo.org & 26 Mar 2010 & Space & 37,150 & 76,376 & Classification \\
Solar Stormwatch & Active & solarstormwatch.com & 22 Feb 2010 & Space & 65,971 & YY,YYY & Classification/Marking \\
Galaxy Zoo: Hubble & Retired & zoo3.galaxyzoo.org & 17 Apr 2010 & Space & XX,XXX & ~200,000 & Classification \\
Moon Zoo & Active & moonzoo.org & 11 May 2010 & Space & 121,251 & 435,314 & Marking \\
Old Weather & Active & oldweather.org & 12 Oct 2010 & Climate & 32,076 & YY,YYY & Transcription \\
The Milkyway Project & Active & milkywayproject.org & 07 Dec 2010 & Space & 57,675 & 35,695 & Marking \\
Planet Hunters & Active & planethunters.org & 16 Dec 2010 & Space & 167,354 & 3,063,759 & Type \\
\hline
Ancient Lives & Active & ancientlives.org & 25 Jul 2011 & Humanities & 24,983 & 153,885 & Transcription \\
Ice Hunters & Retired & icehunters.org & 09 Aug 2011 & Space & 15,276 & YY,YYY & Classification/Marking \\
NEEMO & Active & neemo.zooniverse.org & 15 Oct 2011 & Space & X,XXX & YY,YYY & Classification \\
Whale FM & Active & whale.fm & 29 Nov 2011 & Nature & 2,150 & 15,531 & Classification \\
\hline
SETI Live & Active & setilive.org & 29 Feb 2012 & Space & 63,609 & YY,YYY & Type \\
Galaxy Zoo 4 & Active & galaxyzoo.org & 11 Sep 2012 & Space & 48,550 & 390,907 & Classification \\
Seafloor Explorer & Active & seafloorexplorer.org & 13 Sep 2012 & Nature & 14,099 & 123,077 & Marking \\
Cyclone Center & Active & cyclonecenter.org & 27 Sep 2012 & Climate & 4,767 & 196,638 & Classification \\
Bat Detective & Active & batdetective.org & 02 Oct 2012 & Nature & 1,580 & 582,203 & Classification \\
Cell Slider & Active & cellslider.net & 23 Oct 2012 & Biology & 13,261 & 275,702 & Classification \\
Andromeda Project & Active & andromedaproject.org & 05 Dec 2012 & Space & 5,072 & 12,425 & Marking \\
Snapshot Serengeti & Active & snapshotserengeti.org & 11 Dec 2012 & Nature & 22,173 & 1,240,727 & Classification \\
\hline
Planet Four & Active & planetfour.org & 08 Jan 2013 & Space & 34,718 & 98,920 & Marking \\
Notes from Nature & Active & notesfromnature.org & 22 Apr 2013 & Nature & 3,490 & 123,402 & Marking/Transcription \\
Space Warps & Active & spacewarps.org & 08 May 2013 & Space & 9,544 & 345,240 & Marking \\
Worm Watch Lab & Active & wormwatchlab.org & 30 Jun 2013 & Biology & 3,251 & 74,016 & Classification \\
\hline
\end{tabular}
\end{center}
\label{project-summary}
\end{table*}



% TODO (from Chris): Guide to the Social Science papers that have been written
% TODO add a guide to the Papers that contain project descriptions for each project

\section{Method}
\emph{TO BE WRITTEN LATER}
%% Four sessions were dedicate to performing a group thematic
%% analysis. Participants from the Zooniverse team included the team
%% lead, lead project manager, and two designers of the Planet Hunters
%% application.  Interviews were recorded and transcribed,

%% inductive process which led to the themes for the coding analysis.
%% These themes were used as the basis of a second round of interviews
%% focused on these themes, upon which a second coding process was
%% applied by 3 researchers

\section{The Many Dimensions of a Citizen Science Projects} % Themes? Observations?

\subsection{Key components of a citizen science project}

Despite the development of projects in very different domains of academic research, and which involve disparate user interactions, the core requirements for a successful citizen science project remain stable. A `main' interface allows a \emph{user} to complete a \emph{task} when presented with a \emph{subject}. The task is typically constrained by the tools provided (e.g. answer questions from a decision tree, mark craters on an image) and when completed typically results in the presentation of the next subject to be classified. In Zooniverse projects to date, participants perform tasks individually, and are typically not given control over choice of what subjects to work on. This latter choice makes deliberate manipulation of the data difficult and also ensures that project priorities are respected (i.e. it's not just the beautifu/interesting/easy subjects that are worked on). Secondly, some tutorial elements - either as a stand-alone tutorial, as an interactive within the interface or as surrounding context - are required to acquaint users with their tasks. An additional environment for discussion is typically, but not always, provided allowing for more free-form interaction between users and other participants such as scientists, developers and for which work goes beyond the initial task. Extra tools for manipulated subjects or for exploring contextual information may be provided in association with these discussion environments. 

A community of participants is implicitly necessary for a citizen science project; crowdsourcing without a crowd is a perhaps unsolvable problem. However, levels of participation and involvement in the community will naturally vary; Zooniverse projects typically receive a substantial number of their classifications from users who will never return. A successful citizen science project will thus be designed to both enable these short-term participants to make useful contributions while still fostering longer-term engagement. This need also illustrates the requirement in most cases to assess the ability or accuracy of participants; many projects thus incorporate `tests', either explicitly or more commonly by including simulated or expert-classified subjects in the workflow presented to users. 

%% from emax --- 
% attracting new users' attention
%   + engaging users in general
% getting noobs up to competence
% retaining experienced + most valuable participants
% expanding the user base
% dealing with new data ~
% transferring interest to other projects
% distilling knowledge from contributions : (amalgamating responses into thing)
% selecting the projects - understanding what can be turned into a good Citizen Science project

% almost always needs a discussion space

\subsection{Discussion}

\subsection{Tutorial}

\subsection{Visual Design}

\subsection{Task Design: Presentation considerations}
%% to gameify or not?
McGonigal identified four defining elements of a game: a goal, rules, feedback system and voluntary participation. Other features such as leader boards, badges, the "winning" sensation are all used to reinforce these core concepts but do not create a game environment in their own right \cite{mcgonigal2011reality}. To further this gameplay is a state which encourages an optimistic outlook on personal capabilities, partnered with "invigorating rush of activity" \cite{mcgonigal2011reality}. These concepts would support a science citizen, creating a gameplay state to highly motivate and encourage them to undertake difficult challenges. 

\subsection{Sustaining Engagement}
% Boring project problem - a constraint that led to development and
% technological change
% Old Weather : Adding context

%% did they create rules - placing limitations to achieving the goal -> make a challenge
%% what feedback system did they use and what was the overall goal

%% icebergs/seal hunting : people really wanted a seal. :( 
%% audio :: 
%% posters vs 

%% adding context: old weather
%% achieving flow state

\subsection{Interaction Flow}
% jump straight to action, no introductory video
% start with 1 GS, interleave gold standards w/ real things

% transcribe bentham
% sad museum one 

%% \subsection{Forums}
%% Forums -> 
%% Introduction of Talk 1.0 -> 
%% Introduction of Talk 2.0
%% Organisation and Fragmentation 
%% Top level organisation, moderators, scientists and how this has changed and impacted 
In a study investigating the effect of instructors on forum participation, Mazzolini and Maddison found that instructors who posted frequently on a forum on average produced shorter discussion threads \cite{mazzolini2003sage}. In the Zooniverse environment the participation of "moderators" and "scientists" could be hindering the discussion flow between general science citizens. Furthermore there was a negative correlation between instructor initiated conversations and participation, especially in the advanced units\cite{mazzolini2003sage}. 
%% @Neal does this support your findings so far?

%% Success stories: examples of super-moderators who externally test
%% contributions and distill them for the scientists
%% (why only in certain apps and not others?)
%% (how do super moderators affect the community // roles played)

\subsection{Social Engagement}
% favouriting, tweeting, blog posts

\subsection{Outreach}
% wording, how when to spam participants to get them to come back

\subsection{Launching}
% Andromeda and Snapshot Serengeti as case studies

\section{Discussion}

\subsection{Common Myths of Citizen Science}
% \subsection{$D$ Myths of Designing for Citizen-Science}
% \subsection{Myth $X$: Putting new users through a ``tutorial'' is a good idea}
% \subsection{Myth $Y$: Gameification keeps people motivated}
% \subsection{Myth $Z$: Participants become domain experts}
% \subsection{Myth $Z$: Beautiful pictures are necessary}

\subsection{Themes We See Support For}
% \subsection{Design Builds Trust}
% \subsection{What makes a good domain?}

\subsection{Comparison to Other Systems}
% Comparison with Jeremy Bentham project - failed in the sense that required more energy than was gained out of it, 20 people at the end
% YourPaintings
% Be A Martian


\subsection{Unsolved mysteries}

\section{Related work}

% anyone elses' citizen science systems
\emph{Connect related work here with FoldIt, etc}

\section{Conclusion}

\section{Acknowledgments}
Acknowledgments omitted for blind review.

\balance

%% The Zooniverse framework team has derived significant has
%% been successively refined and scaled as the variety of tasks and
%% number of participants have increased.  At its current state,
%% currently having launched $X$ distinct applications for $Y$ scientific
%% domains, including astronomy, zoology, cell and marine biology,
%% archaeology and paleontology.  This platform represents a unique\cite{moore2011facebooking}


%%  These
%% applications, though separate, have been built on top 

%% The experiences from the first were used to derive design goals for
%% the next,

%% The contributions of the 
%% We identify key design challenges

%% especially as the best practices for designing citizen science systems
%% has not yet emerged.  Among the many design challenges include, being
%% able to appeal to participants with an extremely wide range of
%% expertise, ranging from no knowledge of the field to significant
%% background and interest.  Participants naturally feature a diversity
%% of natural competencies, which is manifested in some people being
%% simply much more adept at some tasks than others. Second, people have
%% many different reasons for engaging with citizen science projects, and
%% to sustain engagement, these platforms must appeal to, and engage
%% these different motivating reasons. Finally, there are a large variety
%% of issues pertaining to individual retention, well as supporting
%% various degrees of engagement -- from the ``sunday scientist'' to the
%% ``scienceoholic''.


%% The purpose of this examination of Zooniverse is to both to document
%% the experience gained from launches and iterations of the various
%% applications, comparing these experiences against previously
%% documented in other citizen-science projects.  The observations derive
%% from a lateral examination of the

%% The path from its first experimental app, Galaxy Zoo, to the more than
%% twenty different projects that have launched on the Zooniverse project
%% required generalising the findings from the first project to different
%% kinds of tasks in other scientific domains.

%%  naturally Participants come from a wide
%% audience % with a massive variety of backgrounds and competencies,
%% such systems interface down to the workflow of how participants' input
%% is collated, verified, and provided as feedback to the participants,
%% along with the nature and kind(s) of affordances provided for
%% communicating and discussing remains challenigng

%% interfaces that have
%% appropriate affordances, the and features remains challenging, due
%% to the wide number of design considerations that mustbe taken
%% jointly into account.

%% Wide variety of expertise

% \section{Background: Brief History of Zooniverse}

% \emph{For the CSCW readers, outline the history of the development of the system
% including a detailed description}

% \section{Observations through iterations}

% \emph{I was thinking put key design observations here relating to how to cross-domain
% citizen science}




% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
% \small
\bibliographystyle{acm-sigchi}
\bibliography{zooniverse-history}
\end{document}

%% from crw04
%% \begin{algorithm}[tb]
%%   \caption{Overview of our general negotiation process, which is common to all of our strategies.  Let $o_\text{own}$ and $o_\text{opp}$ represent our own and the opponent's latest offers, respectively. $t_c$ is the current time and $u_\tau$ is the aspiration level at time $t_c$.}\label{alg:generic-overview}
%%   \begin{algorithmic}
%%     \FOR{$t_c \in [0,1]$}
%%     \STATE $o_\text{opp} \Leftarrow $ {\sc ReceiveOffer}()
%%     \STATE $u_\tau \Leftarrow $ {\sc SetAspirationLevel}($o_\text{opp}, t_c$)
%%     \IF{{\sc GetUtility}($o_\text{opp}, t_c$) $\geq u_\tau$}
%%     \STATE {\sc AcceptOffer}($o_\text{opp}$)
%%     \RETURN
%%     \ENDIF
%%     \STATE $o_\text{own} \Leftarrow $ {\sc GenerateOffer}($u_\tau$)
%%     \STATE {\sc ProposeOffer}($o_\text{own}$)
%%     \ENDFOR
%%     \end{algorithmic}
%% \end{algorithm}

%%  LocalWords:  artefacts HCI artefact Dropbox Skydrive Google PDF
%%  LocalWords:  LaTeX versioning throughs interactional CDSSes UI LD
%%  LocalWords:  bioinformaticians iPad iCloud iCal favour favourite
%%  LocalWords:  microformats picoformats WebDAV situ VCS scm priori
%%  LocalWords:  Powerpoint CB's CBs each's bulleted parseable OTs
%%  LocalWords:  sub-schemas pre Dourish XLSX csv PPTX PPT ICS CalDAV
%%  LocalWords:  RSS VCF XSLT XLST CSS Dojo PNG
