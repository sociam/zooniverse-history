\documentclass{sigchi}

% Use this command to override the default ACM copyright statement (e.g. for preprints). 
% Consult the conference website for the camera-ready copyright statement.
\toappear{}

% Arabic page numbers for submission. 
% Remove this line to eliminate page numbers for the camera ready copy
%\pagenumbering{arabic}


% Load basic packages
\usepackage{balance}  % to better equalize the last page
\usepackage{graphics} % for EPS, load graphicx instead
\usepackage{times}    % comment if you want LaTeX's default font
\usepackage{url}      % llt: nicely formatted URLs
\usepackage{algorithm,algorithmic}

% llt: Define a global style for URLs, rather that the default one
\makeatletter
\def\url@leostyle{%
  \@ifundefined{selectfont}{\def\UrlFont{\sf}}{\def\UrlFont{\small\bf\ttfamily}}}
\makeatother
\urlstyle{leo}


% To make various LaTeX processors do the right thing with page size.
\def\pprw{8.5in}
\def\pprh{11in}
\special{papersize=\pprw,\pprh}
\setlength{\paperwidth}{\pprw}
\setlength{\paperheight}{\pprh}
\setlength{\pdfpagewidth}{\pprw}
\setlength{\pdfpageheight}{\pprh}

% Make sure hyperref comes last of your loaded packages, 
% to give it a fighting chance of not being over-written, 
% since its job is to redefine many LaTeX commands.
\usepackage[pdftex]{hyperref}
\hypersetup{
pdftitle={SIGCHI Conference Proceedings Format},
pdfauthor={LaTeX},
pdfkeywords={SIGCHI, proceedings, archival format},
bookmarksnumbered,
pdfstartview={FitH},
colorlinks,
citecolor=black,
filecolor=black,
linkcolor=black,
urlcolor=black,
breaklinks=true,
}

% create a shortcut to typeset table headings
\newcommand\tabhead[1]{\small\textbf{#1}}

% End of preamble. Here it comes the document.
\begin{document}

\title{One Does Not `Simply' Launch a Citizen Science Project: Reflections on Zooniverse, a Multi-Domain Science Platform}
% \title{A Brief History of Zooniverse: Designing for Multi-Domain Citizen Science}

\numberofauthors{1} \author{ (Authors removed for reviewing) }
\maketitle

\begin{abstract}

\end{abstract}

\keywords{Citizen science, crowdsourcing, interface design}

%% TODO 
\category{H.5.m.}{Information Interfaces and Presentation (e.g. HCI)}{Miscellaneous}

%% TODO 
%% \terms{}

\section{Introduction}

Web-based ``citizen-science'' projects have enabled tens of thousands
of untrained human volunteers to contribute to open scientific
problems across a variety of domains \cite{citizen-science}.  The
handful of successful systems have demonstrated that citizen science
applications can be valuable both to participants, as educational
tools and cognitively-stimulating puzzles, as well as to scientific
researchers who have large unmanageable data sets and problem spaces.

However, designing successful citizen science systems that can be
mutually beneficial in this way while sustaining participation over
time can be exceedingly difficult.  The reasons are several: first,

due to the emerging nature of the field, key design principles and
\emph{best practices} are not yet known or established.  The unique
aspects of designing for citizen science mean that conventional design
methods pioneered for human computation approaches only apply to a
limited extent.  For example, human computation systems often apply
extrinsic motivation (e.g., direct rewards) to drive participation,
while most citizen science participation systems derive from intrinsic
motivations of individuals \cite{extrinsic-vs-intrinsic}.  Since such
motivations are typically personal and idiosyncratic, designing to
drive sustained attention to them is challenging, requiring an
understanding of their nature and the activities that inspire them.
Moreover, participants naturally engage with citizen science systems
in a variety of different ways, and feature a diversity of natural
competencies, manifesting in great variation among the ways people
interact with the system \cite{raddick}. Finally, the simple fact
that, over time, people are likely to simply forget about any
particular system, as their attention is turned away towards other,
newer systems and activities means that retaining those crucial
participants who have accrued a degree of experience and competence in
their tasks is significantly challenging.

In this paper, we contribute a detailed case-study of a unique
citizen-science platform which expanded from a single domain
experiment to what has been considered a ``factory for citizen
science'', an authority for generating successful apps for scientists
with difficult problems independent of any particular domain.  Our
analysis, conducted as retrospective reflective interviews with key
members of the Zooniverse team, aimed to identify the essential
lessons learned through the trial and error process that resulted from
designing each app after the previous as an iterative process.  This
process that allowed the team to systematically explore design
variations at mutiple levels, from the interface/intraction flow, to
the design of social elements (discussion forums), to external
considerations such as ways to best launch and sustain prolonged
engagement through external communications.

The goal of the this paper is to, first, document the informal
knowledge gathered by the Zoonvierse team pertaining to how to design
successful citizen science projects, based on their experience of
launching $X$ projects since the project's genesis.  These insights
are then discussed in the greater context of human computation, to
derive design recommendations and discuss factors that may be
responsible for the observations made.  We begin with a short history
of the project in order to provide readers a context for the following
discussion, followed by a grounded dimensional design analysis of
particular aspects of Zooniverse's deployment.  Finally, we discuss 
Zooniverse's team's perspective of the greatest difficulties for
building more effective citizen science: <X>, <Y> and <Z>, and
ways that HCI research may be able to help.

\section{Background: A Brief History of the Zooniverse}

\emph{TODO: Can someone fill this in?}

As documented previously by Raddick et al \cite{raddick}, the first
Zooniverse project, Galaxy Zoo,designed to engage volunteers in the
morphological classification of images of galaxies, launched in July
2007\cite{galaxyzoo-launch}. 

\emph{AND THEN STUFF HAPPENED!}  

As of September 2013, the most recent projects were \emph{Worm Watch
  Lab}, launched in June 2013, $20$th project to launch

Table $X$ lists all of the Zooniverse projects, launch dates, sizes of
data sets and classifications as of September 2013.  Figure $Y$,
likewise, illustrates the growth of the project from June 2007 until
September 2013.

\section{Method}

\emph{TO BE WRITTEN BY RAMINE AND EMAX}

Four day-long semi-structured interview sessions with the Zooniverse
team were conducted. Participants from the Zooniverse team included
the team lead, lead project manager, and two designers of the Planet
Hunters application.  Interviews were recorded and transcribed,

inductive process which led to the themes for the coding analysis.
These themes were used as the basis of a second round of interviews
focused on these themes, upon which a second coding process was
applied by 3 researchers

\section{Launching a Citizen Science Project}

% attracting new users' attention
%   + engaging users in general
% getting noobs up to competence
% retaining experienced + most valuable participants
% expanding the user base
% dealing with new data ~
% transferring interest to other projects
% distilling knowledge from contributions : (amalgamating responses into thing)
% selecting the projects - understanding what can be turned into a good Citizen Science project

\subsection{Task Design: Presentation considerations}

%% to gameify or not?
McGonigal identified four defining elements of a game: a goal, rules, feedback system and voluntary participation. Other features such as leader boards, badges, the "winning" sensation are all used to reinforce these core concepts but do not create a game environment in their own right. \cite{mcgonigal2011reality} To further this gameplay is a state which encourages an optimistic outlook on personal capabilities, partnered with "invigorating rush of activity". \cite{mcgonigal2011reality} These concepts would support a science citizen, creating a gameplay state to highly motivate and encourage them to undertake difficult challenges. 

%% did they create rules - placing limitations to achieving the goal -> make a challenge
%% what feedback system did they use and what was the overall goal

%% icebergs/seal hunting : people really wanted a seal. :( 
%% audio :: 
%% posters vs 

%% adding context: old weather
%% achieving flow state

\subsection{Interaction Flow}

% jump straight to action, no introductory video
% start with 1 GS, interleave gold standards w/ real things

% transcribe bentham
% sad museum one 

\subsection{Forums}

%% Forums -> 
%% Introduction of Talk 1.0 -> 
%% Introduction of Talk 2.0
%% Organisation and Fragmentation 
%% Top level organisation, moderators, scientists and how this has changed and impacted 

%% Success stories: examples of super-moderators who externally test
%% contributions and distill them for the scientists
%% (why only in certain apps and not others?)
%% (how do super moderators affect the community // roles played)

\subsection{Social Engagement}

% favouriting, tweeting, blog posts

\subsection{Outreach}

% wording, how when to spam participants to get them to come back

\subsection{Launching}

% holding back subjects

\section{Discussion}

%% gameification 
%%  sometimes works, some settings don't work

% \subsection{$D$ Myths of Designing for Citizen-Science}
% \subsection{Myth $X$: Putting new users through a ``tutorial'' is a good idea}
% \subsection{Myth $Y$: Gameification keeps people motivated}
% \subsection{Myth $Z$: Participants become domain experts}

\section{Related work}

% anyone elses' citizen science systems
\emph{Connect related work here with FoldIt, etc}

\section{Discussion}

\section{Conclusion}

\section{Acknowledgments}
Acknowledgments omitted for blind review.

\balance

%% The Zooniverse framework team has derived significant has
%% been successively refined and scaled as the variety of tasks and
%% number of participants have increased.  At its current state,
%% currently having launched $X$ distinct applications for $Y$ scientific
%% domains, including astronomy, zoology, cell and marine biology,
%% archaeology and paleontology.  This platform represents a unique\cite{moore2011facebooking}


%%  These
%% applications, though separate, have been built on top 

%% The experiences from the first were used to derive design goals for
%% the next,

%% The contributions of the 
%% We identify key design challenges

%% especially as the best practices for designing citizen science systems
%% has not yet emerged.  Among the many design challenges include, being
%% able to appeal to participants with an extremely wide range of
%% expertise, ranging from no knowledge of the field to significant
%% background and interest.  Participants naturally feature a diversity
%% of natural competencies, which is manifested in some people being
%% simply much more adept at some tasks than others. Second, people have
%% many different reasons for engaging with citizen science projects, and
%% to sustain engagement, these platforms must appeal to, and engage
%% these different motivating reasons. Finally, there are a large variety
%% of issues pertaining to individual retention, well as supporting
%% various degrees of engagement -- from the ``sunday scientist'' to the
%% ``scienceoholic''.


%% The purpose of this examination of Zooniverse is to both to document
%% the experience gained from launches and iterations of the various
%% applications, comparing these experiences against previously
%% documented in other citizen-science projects.  The observations derive
%% from a lateral examination of the

%% The path from its first experimental app, Galaxy Zoo, to the more than
%% twenty different projects that have launched on the Zooniverse project
%% required generalising the findings from the first project to different
%% kinds of tasks in other scientific domains.

%%  naturally Participants come from a wide
%% audience % with a massive variety of backgrounds and competencies,
%% such systems interface down to the workflow of how participants' input
%% is collated, verified, and provided as feedback to the participants,
%% along with the nature and kind(s) of affordances provided for
%% communicating and discussing remains challenigng

%% interfaces that have
%% appropriate affordances, the and features remains challenging, due
%% to the wide number of design considerations that mustbe taken
%% jointly into account.

%% Wide variety of expertise

% \section{Background: Brief History of Zooniverse}

% \emph{For the CSCW readers, outline the history of the development of the system
% including a detailed description}

% \section{Observations through iterations}

% \emph{I was thinking put key design observations here relating to how to cross-domain
% citizen science}




% If you want to use smaller typesetting for the reference list,
% uncomment the following line:
% \small
\bibliographystyle{acm-sigchi}
\bibliography{zooniverse-history}
\end{document}

%% from crw04
%% \begin{algorithm}[tb]
%%   \caption{Overview of our general negotiation process, which is common to all of our strategies.  Let $o_\text{own}$ and $o_\text{opp}$ represent our own and the opponent's latest offers, respectively. $t_c$ is the current time and $u_\tau$ is the aspiration level at time $t_c$.}\label{alg:generic-overview}
%%   \begin{algorithmic}
%%     \FOR{$t_c \in [0,1]$}
%%     \STATE $o_\text{opp} \Leftarrow $ {\sc ReceiveOffer}()
%%     \STATE $u_\tau \Leftarrow $ {\sc SetAspirationLevel}($o_\text{opp}, t_c$)
%%     \IF{{\sc GetUtility}($o_\text{opp}, t_c$) $\geq u_\tau$}
%%     \STATE {\sc AcceptOffer}($o_\text{opp}$)
%%     \RETURN
%%     \ENDIF
%%     \STATE $o_\text{own} \Leftarrow $ {\sc GenerateOffer}($u_\tau$)
%%     \STATE {\sc ProposeOffer}($o_\text{own}$)
%%     \ENDFOR
%%     \end{algorithmic}
%% \end{algorithm}

%%  LocalWords:  artefacts HCI artefact Dropbox Skydrive Google PDF
%%  LocalWords:  LaTeX versioning throughs interactional CDSSes UI LD
%%  LocalWords:  bioinformaticians iPad iCloud iCal favour favourite
%%  LocalWords:  microformats picoformats WebDAV situ VCS scm priori
%%  LocalWords:  Powerpoint CB's CBs each's bulleted parseable OTs
%%  LocalWords:  sub-schemas pre Dourish XLSX csv PPTX PPT ICS CalDAV
%%  LocalWords:  RSS VCF XSLT XLST CSS Dojo PNG
